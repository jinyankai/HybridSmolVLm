SmolVLMConfig {
  "architectures": [
    "Idefics3ForConditionalGeneration"
  ],
  "image_seq_len": 81,
  "image_token_id": 49153,
  "model_type": "smolvlm",
  "pad_token_id": 128002,
  "scale_factor": 3,
  "text_config": {
    "_flash_attn_2_enabled": true,
    "_name_or_path": "/fsx/m4/experiments/local_experiment_dir/s3_async_temporary_checkpoint_folder/tr_324_opt_400/unwrapped_model",
    "architectures": [
      "VLlama3ForCausalLM"
    ],
    "attention_bias": false,
    "attention_dropout": 0.0,
    "bos_token_id": 0,
    "eos_token_id": 0,
    "head_dim": 64,
    "hidden_act": "silu",
    "hidden_size": 2048,
    "initializer_range": 0.02,
    "intermediate_size": 8192,
    "max_position_embeddings": 16384,
    "mlp_bias": false,
    "model_type": "llama",
    "neftune_noise_alpha": 0.0,
    "num_attention_heads": 32,
    "num_hidden_layers": 24,
    "num_key_value_heads": 32,
    "pad_token_id": 2,
    "perceiver_config": {
      "_name_or_path": "",
      "add_cross_attention": false,
      "architectures": null,
      "attention_dropout": 0.0,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "decoder_start_token_id": null,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "early_stopping": false,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "hidden_act": "silu",
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "max_length": 20,
      "min_length": 0,
      "model_type": "vllama3",
      "no_repeat_ngram_size": 0,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_key_value_heads": 1,
      "num_return_sequences": 1,
      "output_attentions": false,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "qk_layer_norms_perceiver": false,
      "remove_invalid_values": false,
      "repetition_penalty": 1.0,
      "resampler_depth": 6,
      "resampler_head_dim": 96,
      "resampler_n_heads": 16,
      "resampler_n_latents": 64,
      "return_dict": true,
      "return_dict_in_generate": false,
      "sep_token_id": null,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": true,
      "tokenizer_class": null,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": null,
      "torchscript": false,
      "transformers_version": "4.46.0",
      "typical_p": 1.0,
      "use_bfloat16": false
    },
    "pretraining_tp": 1,
    "qk_layer_norms": false,
    "rms_norm_eps": 1e-05,
    "rope_scaling": null,
    "rope_theta": 273768.0,
    "torch_dtype": "bfloat16",
    "use_cache": true,
    "use_resampler": false,
    "vocab_size": 49155
  },
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers.js_config": {
    "dtype": {
      "decoder_model_merged": "q4",
      "embed_tokens": "auto",
      "vision_encoder": "auto"
    },
    "kv_cache_dtype": {
      "fp16": "float16",
      "q4f16": "float16"
    },
    "use_external_data_format": {
      "decoder_model_merged.onnx": true,
      "decoder_model_merged_fp16.onnx": true
    }
  },
  "transformers_version": "4.53.1",
  "use_cache": true,
  "vision_config": {
    "attention_dropout": 0.0,
    "hidden_act": "gelu_pytorch_tanh",
    "hidden_size": 1152,
    "image_size": 384,
    "initializer_range": 0.02,
    "intermediate_size": 4304,
    "layer_norm_eps": 1e-06,
    "max_image_size": {
      "longest_edge": 384
    },
    "model_type": "smolvlm_vision",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 27,
    "patch_size": 14,
    "size": {
      "longest_edge": 1920
    },
    "tie_word_embeddings": false,
    "torch_dtype": "bfloat16"
  },
  "vocab_size": 49155
}

Idefics3Processor:
- image_processor: Idefics3ImageProcessor {
  "do_convert_rgb": true,
  "do_image_splitting": true,
  "do_normalize": true,
  "do_pad": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_processor_type": "Idefics3ImageProcessor",
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "max_image_size": {
    "longest_edge": 384
  },
  "processor_class": "Idefics3Processor",
  "resample": 1,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "longest_edge": 1536
  }
}

- tokenizer: GPT2TokenizerFast(name_or_path='HuggingFaceTB/SmolVLM-Instruct', vocab_size=49152, model_max_length=16384, is_fast=True, padding_side='right', truncation_side='left', special_tokens={'bos_token': '<|im_start|>', 'eos_token': '<end_of_utterance>', 'unk_token': '<|endoftext|>', 'pad_token': '<|im_end|>', 'additional_special_tokens': ['<fake_token_around_image>', '<image>', '<end_of_utterance>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
        0: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        1: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        2: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        3: AddedToken("<repo_name>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        4: AddedToken("<reponame>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        5: AddedToken("<file_sep>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        6: AddedToken("<filename>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        7: AddedToken("<gh_stars>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        8: AddedToken("<issue_start>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        9: AddedToken("<issue_comment>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        10: AddedToken("<issue_closed>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        11: AddedToken("<jupyter_start>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        12: AddedToken("<jupyter_text>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        13: AddedToken("<jupyter_code>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        14: AddedToken("<jupyter_output>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        15: AddedToken("<jupyter_script>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        16: AddedToken("<empty_output>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        49152: AddedToken("<fake_token_around_image>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        49153: AddedToken("<image>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
        49154: AddedToken("<end_of_utterance>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
)

{
  "image_seq_len": 81,
  "processor_class": "Idefics3Processor"
}


